{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"200\" src=\"img/kschool.png\"></img>\n",
    "<h1 style=\"font-size: 2.5em\"> Recomendador de Películas MovieLens</h1>\n",
    "\n",
    "<span style=\"float: right; text-align: right;\">Jorge Ayuso Rejas<br>Abril 2016</span>\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "En el siguiente *notebook* vamos a trabajar con los datos de [MovieLens](https://movielens.org/) y con Spark\n",
    "para hacer recomendaciones de películas y profundizar en los sistemas de recomendación basados en filtros colaborativos.\n",
    "\n",
    "Para ello nos basamos en el siguiente [guión](https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html) del Spark Summit 2014.\n",
    "\n",
    "### Antes de empezar\n",
    "\n",
    "Necesitamos descargar los datos en la carpeta `../datos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -l ../datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** Si no existen las carpetas `ml-1m` y `tag-genome` usamos el script `descargar_movilens.sh` para descargarlos.\n",
    "\n",
    "## Los datos\n",
    "\n",
    "En la carpeta `ml-1m`  que contiene: \n",
    "\n",
    "> Stable benchmark dataset. 1 million ratings from 6000 users on 4000 movies. Released 2/2003.\n",
    "\n",
    "Hemos descargado estos datos que son pequeños para hacer las pruebas, pero el sistema que vamos a utilizar con Spark es distribuido y lo podríamos hacer sobre un cluster con el mismo código para datos más grandes.\n",
    "\n",
    "\n",
    "Los datos que incluye MovieLens son:\n",
    "\n",
    "* `movies.dat`: Incluye el catálogo de películas separado por `::` cada campo.\n",
    "* `ratings.dat`: Incluye los ratings entre usuarios y películas en este caso la puntuación (de 1 a 5) que han dado a esa película. Este archivo es nuestra matriz $M_{(n,p)}$ .\n",
    "* `users.dat`: Incluye información de los usuarios pero en nuestro ejercicio no vamos a utilizar este archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head ../datos/ml-1m/movies.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head ../datos/ml-1m/ratings.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incluirnos en el recomendador\n",
    "\n",
    "Una de las características importantes de los sitemas de recomendación basados en factorización de matrices. Es que desde el entrenamiendo del modelo tendremos que incluir a todos los usuarios a los que vamos a querer recomendar. Al contrario que otros modelos de *machine learning* donde una vez entrenado el modelo podemos predecir a nuevos usuarios.\n",
    "\n",
    "Para ello vamos a incluir nuestras preferencias como un nuevo usuario y después veremos las recomendaciones que obtenemos para nosotros mismos.\n",
    "\n",
    "¿Cómo hacemos esto?\n",
    "\n",
    "El siguiente script en python `spark_als/bin/rateMovies` sirve para generar nuestras recomendaciones.\n",
    "\n",
    "Una vez ejecutado se crearán nuestros ratings en el archivo `personalRatings.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat personalRatings.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark y MLlib\n",
    "\n",
    "Para nuestro recomendador vamos a usar Spark y la librería MLlib que incluye el algoritmo ALS:    \n",
    "\n",
    "&nbsp;<br>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://databricks-training.s3.amazonaws.com/img/matrix_factorization.png\" width=\"550\"><img>\n",
    "http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html\n",
    "</center>\n",
    "\n",
    "\n",
    "Lo primero de todo comprobamos que tenemos creado el `SparkContext`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos tiene que devolver algo del estilo:\n",
    "\n",
    "```\n",
    "<pyspark.context.SparkContext at 0x7f4250d6aa10>\n",
    "\n",
    "```\n",
    "\n",
    "Además debemos de ver la web del Spark UI en http://127.0.0.1:4040/.\n",
    "\n",
    "Empezamos con el proceso de Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cargamos librería necesarias para los scripts\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Cargamos las funciones definidas en el archivo funciones_auxiliares.py\n",
    "\n",
    "from funciones_auxiliares import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la función `loadRatings` para cargar nuestros ratings personales: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRatings = loadRatings(\"personalRatings.txt\")\n",
    "myRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos los datos a un `RDD`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myRatingsRDD = sc.parallelize(myRatings, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la carpeta donde se encuentras nuestros archivos y usamos la función `parseRating` de manera distribuida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieLensHomeDir = \"../datos/ml-1m/\"\n",
    "ratings = sc.textFile(join(movieLensHomeDir, \"ratings.dat\")).map(parseRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalemente el tamaño de items, en nuestro caso películas, es un número razonable y que nos cabe bien en la memoría RAM del *driver*. En general es $n$ (el tamaño de usuarios) el que suele tener un tamaño grande $p << n$.    \n",
    "\n",
    "Por ese motivo podemos hacer un `collect` sobre el `RDD` de las películas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies = dict(sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie).collect())\n",
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados ambos archivos vamos a contar el número de películas, usuarios y ratings que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numRatings = ratings.count()\n",
    "numUsers = ratings.values().map(lambda r: r[0]).distinct().count()\n",
    "numMovies = ratings.values().map(lambda r: r[1]).distinct().count()\n",
    "print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego siguiendo nuestra notación tenemos que:\n",
    "\n",
    "* $n=6040$\n",
    "* $p=3706$\n",
    "\n",
    "Así que la matriz $M$ tiene un tamaño de $6040\\cdot3706=22384240$ pero solo tenemos información de $1000209$, es decir un 4%.\n",
    "\n",
    "### Entrenamiento de los parámetros\n",
    "\n",
    "Para dedicir qué parámetros utilizar en nuestro algoritmo vamos a dividir la muestra en tres trozos:\n",
    "entrenamiento (60%), validación (20%) y test (20%). Para ello lo hacemos basado en el último digito del `timestamp` \n",
    "(ver la función `parseRating` línea 12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPartitions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = (\n",
    "      ratings.filter(lambda x: x[0] < 6)\n",
    "      .values()\n",
    "      .union(myRatingsRDD)\n",
    "      .repartition(numPartitions)\n",
    "      .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = (\n",
    "      ratings.filter(lambda x: x[0] >= 6 and x[0] < 8)\n",
    "      .values()\n",
    "      .repartition(numPartitions)\n",
    "      .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = (\n",
    "    ratings.filter(lambda x: x[0] >= 8)\n",
    "    .values()\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numTraining = training.count()\n",
    "numValidation = validation.count()\n",
    "numTest = test.count()\n",
    "\n",
    "print \"Training: %d, validation: %d, test: %d\" % (numTraining, numValidation, numTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionamos ahora los posibles valores de nuestros parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = [8, 12]\n",
    "lambdas = [0.1, 10.0]\n",
    "numIters = [10, 20]\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Con `itertools.product` generamos la malla de posibilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    model = ALS.train(training, rank, numIter, lmbda)\n",
    "    validationRmse = computeRmse(model, validation, numValidation)\n",
    "    print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \\\n",
    "          \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
    "    if (validationRmse < bestValidationRmse):\n",
    "        bestModel = model\n",
    "        bestValidationRmse = validationRmse\n",
    "        bestRank = rank\n",
    "        bestLambda = lmbda\n",
    "        bestNumIter = numIter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluamos el mejor modelo (guardado en `bestModel`) con la partición de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRmse = computeRmse(bestModel, test, numTest)\n",
    "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
    "  + \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejercicio habitual en *machine learning* es comparar el resultado de nuestro modelo con el *baseline*. En este caso con la media de los ratings y ver si nuestro modelo es mejor y en cuanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanRating = training.union(validation).map(lambda x: x[2]).mean()\n",
    "baselineRmse = sqrt(test.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / numTest)\n",
    "improvement = (baselineRmse - testRmse) / baselineRmse * 100\n",
    "print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final\n",
    "Terminamos entrenando el modelo final con todos los datos y los parámetros que hemos elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = (ratings\n",
    "          .values()\n",
    "          .union(myRatingsRDD)\n",
    "          .repartition(numPartitions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalModel = ALS.train(final, bestRank, bestNumIter, bestLambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver nuestras recomendaciones\n",
    "\n",
    "Vamos a recuperar las recomendaciones según los ratings que pusimos al principio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myRatedMovieIds = set([x[1] for x in myRatings])\n",
    "candidates = sc.parallelize([m for m in movies if m not in myRatedMovieIds])\n",
    "predictions = finalModel.predictAll(candidates.map(lambda x: (0, x))).collect()\n",
    "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Movies recommended for you:\"\n",
    "for i in xrange(len(recommendations)):\n",
    "    print (u\"%2d | (Rating: %.3f) | %s\" % (i + 1 ,recommendations[i][2], movies[recommendations[i][1]] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendiendo cómo se realizan las predicciones\n",
    "Vamos a entender qué descomposición se ha realizado y cómo se realizan las predicciones. \n",
    "La matriz de ratings tiene tamaño $(6041\\times3706)$ como hemos visto y en el entranimiento se ha decidio utilizar 12 variables latentes luego la descomposición que hemos realizado es:\n",
    "&nbsp;<br>\n",
    "&nbsp;<br>\n",
    "\n",
    "$$\n",
    "{\\Large\n",
    "M_{(6041\\times 3706)} = U_{(6041\\times 12)}\\;V_{(12 \\times 3706)}\n",
    "}\n",
    "$$\n",
    "\n",
    "¿Dónde están esas matrices calculadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.userFeatures().take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(finalModel.userFeatures().take(1)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.userFeatures().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.productFeatures().take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.productFeatures().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto el objeto `finalModel` además contiene varias funciones para hacer las predicciones, pero vamos a hacerlo a mano para entender cómo funciona algebráicamente. \n",
    "\n",
    "Para ello vamos a usar de ejemplo los datos de nuestras recomendacions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueso id de usuario es el 0 así que podemos quedanos con la fila de la matriz $U$ que hace referencia a nuestro usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_feature = finalModel.userFeatures().filter(lambda x: x[0]==0).collect()[0]\n",
    "user_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperamos nuestra primera recomendación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommendations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos de la columna $V$ la columna correspondiente con esta película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_features = finalModel.productFeatures().filter(lambda x: x[0] == recommendations[0][1]).collect()[0]\n",
    "product_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar, es fácil de comprobar que matemáticamente:\n",
    "$$\n",
    "{\\Large\n",
    "m_{ij} =\\; <u_i,v_j>\n",
    "}\n",
    "$$\n",
    "\n",
    "Es decir, el rating del usuario $i$ y el item $j$ es el producto escalar de la fila  $i$-esima de la matriz $U$ y la columna $j$-esima de la matriz $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(np.array(user_feature[1]),np.array(product_features[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
